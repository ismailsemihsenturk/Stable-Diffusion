{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {\n",
    "        \"cellView\": \"form\",\n",
    "        \"id\": \"x_dhQfFYXoPu\"\n",
    "      },\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"import model_loader\\n\",\n",
    "        \"import pipeline\\n\",\n",
    "        \"from PIL import Image\\n\",\n",
    "        \"from pathlib import Path\\n\",\n",
    "        \"from transformers import CLIPTokenizer\\n\",\n",
    "        \"import torch\\n\",\n",
    "        \"\\n\",\n",
    "        \"DEVICE = \\\"cpu\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"ALLOW_CUDA = False\\n\",\n",
    "        \"ALLOW_MPS = False\\n\",\n",
    "        \"\\n\",\n",
    "        \"if torch.cuda.is_available() and ALLOW_CUDA:\\n\",\n",
    "        \"    DEVICE = \\\"cuda\\\"\\n\",\n",
    "        \"elif (torch.has_mps or torch.backends.mps.is_available()) and ALLOW_MPS:\\n\",\n",
    "        \"    DEVICE = \\\"mps\\\"\\n\",\n",
    "        \"print(f\\\"Using device: {DEVICE}\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"tokenizer = CLIPTokenizer(\\\"../data/vocab.json\\\", merges_file=\\\"../data/merges.txt\\\")\\n\",\n",
    "        \"model_file = \\\"../data/v1-5-pruned-emaonly.ckpt\\\"\\n\",\n",
    "        \"models = model_loader.preload_models_from_standard_weights(model_file, DEVICE)\\n\",\n",
    "        \"\\n\",\n",
    "        \"## TEXT TO IMAGE\\n\",\n",
    "        \"\\n\",\n",
    "        \"# prompt = \\\"A dog with sunglasses, wearing comfy hat, looking at camera, highly detailed, ultra sharp, cinematic, 100mm lens, 8k resolution.\\\"\\n\",\n",
    "        \"prompt = \\\"A cat stretching on the floor, highly detailed, ultra sharp, cinematic, 100mm lens, 8k resolution.\\\"\\n\",\n",
    "        \"uncond_prompt = \\\"\\\"  # Also known as negative prompt\\n\",\n",
    "        \"do_cfg = True\\n\",\n",
    "        \"cfg_scale = 8  # min: 1, max: 14\\n\",\n",
    "        \"\\n\",\n",
    "        \"## IMAGE TO IMAGE\\n\",\n",
    "        \"\\n\",\n",
    "        \"input_image = None\\n\",\n",
    "        \"# Comment to disable image to image\\n\",\n",
    "        \"image_path = \\\"../images/dog.jpg\\\"\\n\",\n",
    "        \"# input_image = Image.open(image_path)\\n\",\n",
    "        \"# Higher values means more noise will be added to the input image, so the result will further from the input image.\\n\",\n",
    "        \"# Lower values means less noise is added to the input image, so output will be closer to the input image.\\n\",\n",
    "        \"strength = 0.9\\n\",\n",
    "        \"\\n\",\n",
    "        \"## SAMPLER\\n\",\n",
    "        \"\\n\",\n",
    "        \"sampler = \\\"ddpm\\\"\\n\",\n",
    "        \"num_inference_steps = 50\\n\",\n",
    "        \"seed = 42\\n\",\n",
    "        \"\\n\",\n",
    "        \"output_image = pipeline.generate(\\n\",\n",
    "        \"    prompt=prompt,\\n\",\n",
    "        \"    uncond_prompt=uncond_prompt,\\n\",\n",
    "        \"    input_image=input_image,\\n\",\n",
    "        \"    strength=strength,\\n\",\n",
    "        \"    do_cfg=do_cfg,\\n\",\n",
    "        \"    cfg_scale=cfg_scale,\\n\",\n",
    "        \"    sampler_name=sampler,\\n\",\n",
    "        \"    n_inference_steps=num_inference_steps,\\n\",\n",
    "        \"    seed=seed,\\n\",\n",
    "        \"    models=models,\\n\",\n",
    "        \"    device=DEVICE,\\n\",\n",
    "        \"    idle_device=\\\"cpu\\\",\\n\",\n",
    "        \"    tokenizer=tokenizer,\\n\",\n",
    "        \")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Combine the input image and the output image into a single image.\\n\",\n",
    "        \"Image.fromarray(output_image)\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"accelerator\": \"GPU\",\n",
    "    \"colab\": {\n",
    "      \"collapsed_sections\": [\n",
    "        \"iDI2dKfRWTId\"\n",
    "      ],\n",
    "      \"provenance\": []\n",
    "    },\n",
    "    \"gpuClass\": \"standard\",\n",
    "    \"kernelspec\": {\n",
    "      \"display_name\": \"Python 3\",\n",
    "      \"name\": \"python3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"codemirror_mode\": {\n",
    "        \"name\": \"ipython\",\n",
    "        \"version\": 3\n",
    "      },\n",
    "      \"file_extension\": \".py\",\n",
    "      \"mimetype\": \"text/x-python\",\n",
    "      \"name\": \"python\",\n",
    "      \"nbconvert_exporter\": \"python\",\n",
    "      \"pygments_lexer\": \"ipython3\",\n",
    "      \"version\": \"3.11.3\"\n",
    "    }\n",
    "  },\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 0\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
